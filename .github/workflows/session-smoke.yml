name: Session Smoke Test

on:
  workflow_dispatch:
    inputs:
      duration_secs:
        description: 'Duration to run automation (seconds)'
        required: false
        default: '60'
        type: string
      mode:
        description: 'Run mode (dry_run or live)'
        required: false
        default: 'dry_run'
        type: choice
        options:
          - dry_run
          - live
  pull_request:
    types: [opened, synchronize]
    # Optional: uncomment to enable automatic smoke tests on PRs
    # paths:
    #   - 'automation/**'
    #   - 'core/**'
    #   - 'scripts/**'

jobs:
  setup:
    name: Setup
    runs-on: ubuntu-latest
    outputs:
      python-version: ${{ steps.setup-python.outputs.python-version }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        id: setup-python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

  deps:
    name: Install Dependencies
    runs-on: ubuntu-latest
    needs: setup
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ needs.setup.outputs.python-version }}
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "requirements.txt not found, installing minimal dependencies"
            pip install pandas numpy python-dotenv pydantic
          fi

  smoke:
    name: Run Smoke Test
    runs-on: ubuntu-latest
    needs: [setup, deps]
    env:
      DRY_RUN: ${{ github.event.inputs.mode == 'live' && 'false' || 'true' }}
      BROKER_NAME: binance
      BINANCE_BASE_URL: https://testnet.binance.vision
      PYTHONUNBUFFERED: '1'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ needs.setup.outputs.python-version }}
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pandas numpy python-dotenv pydantic
          fi

      - name: Run automation smoke test
        run: |
          DURATION=${{ github.event.inputs.duration_secs || '60' }}
          echo "Running automation for ${DURATION} seconds in DRY_RUN=${DRY_RUN} mode"
          python scripts/run_automation.py --duration ${DURATION} --enable-validation

      - name: Check session data created
        run: |
          ls -lah data/session/ || echo "No session data directory"
          if [ -f data/session/events.jsonl ]; then
            echo "events.jsonl created ($(wc -l < data/session/events.jsonl) lines)"
          else
            echo "Warning: events.jsonl not found"
          fi
          if [ -f data/session/summary.json ]; then
            echo "summary.json created"
            cat data/session/summary.json
          else
            echo "Warning: summary.json not found"
          fi

      - name: Upload session data for validation
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: session-data-raw
          path: data/session/
          retention-days: 7

  validate:
    name: Validate Session Data
    runs-on: ubuntu-latest
    needs: [setup, smoke]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ needs.setup.outputs.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pydantic

      - name: Download session data
        uses: actions/download-artifact@v4
        with:
          name: session-data-raw
          path: data/session/

      - name: Validate session data
        run: |
          python scripts/validate_session.py

  artifacts:
    name: Upload Artifacts
    runs-on: ubuntu-latest
    needs: [smoke, validate]
    if: always()
    steps:
      - name: Download session data
        uses: actions/download-artifact@v4
        with:
          name: session-data-raw
          path: session-data/

      - name: Create artifact summary
        run: |
          echo "Session Smoke Test Artifacts" > session-data/README.txt
          echo "=============================" >> session-data/README.txt
          echo "" >> session-data/README.txt
          echo "Generated: $(date -u)" >> session-data/README.txt
          echo "Run ID: ${{ github.run_id }}" >> session-data/README.txt
          echo "Mode: ${{ github.event.inputs.mode || 'dry_run' }}" >> session-data/README.txt
          echo "Duration: ${{ github.event.inputs.duration_secs || '60' }}s" >> session-data/README.txt
          echo "" >> session-data/README.txt
          echo "Files:" >> session-data/README.txt
          ls -lh session-data/ >> session-data/README.txt

      - name: Upload final artifacts
        uses: actions/upload-artifact@v4
        with:
          name: session-data
          path: session-data/
          retention-days: 30

  summary:
    name: Generate Summary
    runs-on: ubuntu-latest
    needs: [setup, smoke, validate]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ needs.setup.outputs.python-version }}

      - name: Download session data
        uses: actions/download-artifact@v4
        with:
          name: session-data-raw
          path: data/session/
        continue-on-error: true

      - name: Generate summary
        run: |
          echo "# Session Smoke Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Configuration:**" >> $GITHUB_STEP_SUMMARY
          echo "- Mode: \`${{ github.event.inputs.mode || 'dry_run' }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Duration: ${{ github.event.inputs.duration_secs || '60' }} seconds" >> $GITHUB_STEP_SUMMARY
          echo "- Workflow: [\#${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f data/session/summary.json ]; then
            echo "**Session Summary:**" >> $GITHUB_STEP_SUMMARY
            python -c "
          import json, sys
          from datetime import datetime
          with open('data/session/summary.json') as f:
              s = json.load(f)
          print(f\"- Session ID: \\\`{s.get('session_id', 'N/A')}\\\`\")
          print(f\"- Status: **{s.get('status', 'N/A')}**\")
          print(f\"- Phases: {s.get('phases_completed', 0)}/{s.get('phases_total', 3)}\")
          print(f\"- Last Phase: \\\`{s.get('last_phase', 'N/A')}\\\`\")
          if 'totals' in s:
              t = s['totals']
              print(f\"- Total Trades: {t.get('trades', 0)} (Wins: {t.get('wins', 0)}, Losses: {t.get('losses', 0)})\")
          if 'last_updated' in s:
              print(f\"- Last Updated: {s['last_updated']}\")
          " >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è No summary.json found" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f data/session/events.jsonl ]; then
            EVENT_COUNT=$(wc -l < data/session/events.jsonl)
            echo "**Events:**" >> $GITHUB_STEP_SUMMARY
            echo "- Total events: ${EVENT_COUNT}" >> $GITHUB_STEP_SUMMARY
            
            # Count event types
            echo "- Event types:" >> $GITHUB_STEP_SUMMARY
            python -c "
          import json
          from collections import Counter
          types = []
          with open('data/session/events.jsonl') as f:
              for line in f:
                  if line.strip():
                      types.append(json.loads(line).get('type', 'unknown'))
          for etype, count in Counter(types).most_common():
              print(f\"  - \\\`{etype}\\\`: {count}\")
          " >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è No events.jsonl found" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Artifacts:**" >> $GITHUB_STEP_SUMMARY
          echo "- üì¶ [Download session-data](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ Smoke test completed" >> $GITHUB_STEP_SUMMARY

      - name: Comment on PR (optional)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            const fs = require('fs');
            let comment = '## üî¨ Session Smoke Test Results\n\n';
            comment += `**Mode:** \`${{ github.event.inputs.mode || 'dry_run' }}\`\n`;
            comment += `**Duration:** ${{ github.event.inputs.duration_secs || '60' }}s\n\n`;
            
            try {
              const summary = JSON.parse(fs.readFileSync('data/session/summary.json', 'utf8'));
              comment += `**Status:** ${summary.status}\n`;
              comment += `**Phases:** ${summary.phases_completed}/${summary.phases_total}\n`;
              if (summary.totals) {
                comment += `**Trades:** ${summary.totals.trades} (${summary.totals.wins}W/${summary.totals.losses}L)\n`;
              }
            } catch (e) {
              comment += '‚ö†Ô∏è Could not read summary\n';
            }
            
            comment += `\n[View full results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
